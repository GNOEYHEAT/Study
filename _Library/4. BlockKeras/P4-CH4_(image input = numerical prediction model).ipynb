{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width, height))\n",
    "    sub_plt.set_title('R ' + str(y_train[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층퍼셉트론 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 834us/step - loss: 4790.6471 - val_loss: 361.5716\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 270.4457 - val_loss: 253.6413\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 206.1511 - val_loss: 172.8532\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 148.1513 - val_loss: 136.7520\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 107.1865 - val_loss: 154.0889\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 84.3894 - val_loss: 116.8907\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 67.4793 - val_loss: 107.2708\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 53.6074 - val_loss: 107.3573\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 49.9698 - val_loss: 103.3773\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 42.6906 - val_loss: 88.6489\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 32.4652 - val_loss: 95.4204\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 32.5858 - val_loss: 91.6810\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 19.4067 - val_loss: 109.0806\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 16.3404 - val_loss: 89.4148\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 11.1762 - val_loss: 88.1726\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 8.3970 - val_loss: 89.8434\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.1724 - val_loss: 90.0524\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.9780 - val_loss: 88.4343\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.2132 - val_loss: 94.0097\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.4338 - val_loss: 87.9971\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.2879 - val_loss: 90.2694\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.5992 - val_loss: 89.7556\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.1513 - val_loss: 92.5054\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9461 - val_loss: 90.0092\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8313 - val_loss: 92.3147\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5865 - val_loss: 91.2844\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.4096 - val_loss: 90.6018\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4723 - val_loss: 89.5523\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7905 - val_loss: 90.9518\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5849 - val_loss: 90.3494\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6935 - val_loss: 88.8813\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1267 - val_loss: 91.0610\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.1968 - val_loss: 91.2647\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0189 - val_loss: 92.8210\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.8264 - val_loss: 89.9975\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.4221 - val_loss: 91.7944\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 2.7292 - val_loss: 89.9255\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 2.3773 - val_loss: 90.8794\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.6675 - val_loss: 91.0491\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.6314 - val_loss: 87.8254\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8239 - val_loss: 96.3946\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.5156 - val_loss: 109.8045\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 6.8603 - val_loss: 95.0562\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.3127 - val_loss: 91.8984\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 3.3099 - val_loss: 110.3755\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.2548 - val_loss: 92.3747\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.0531 - val_loss: 93.9312\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 5.8773 - val_loss: 115.0889\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 5.8567 - val_loss: 94.3191\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.7919 - val_loss: 92.9661\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.5247 - val_loss: 93.5045\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.9672 - val_loss: 89.7017\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.9248 - val_loss: 89.7220\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.5436 - val_loss: 94.9156\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 5.5044 - val_loss: 93.8940\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 7.9384 - val_loss: 99.6646\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 5.9016 - val_loss: 92.3106\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.5241 - val_loss: 87.9187\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.1728 - val_loss: 88.4341\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.7494 - val_loss: 106.4351\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 7.5811 - val_loss: 90.9458\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 17.4504 - val_loss: 97.1815\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 22.2623 - val_loss: 88.2006\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 10.7631 - val_loss: 94.2095\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 5.2191 - val_loss: 102.6836\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.1957 - val_loss: 93.5649\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 6.6081 - val_loss: 88.4401\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 9.3473 - val_loss: 95.7301\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.3050 - val_loss: 102.5940\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.4732 - val_loss: 88.8056\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7790 - val_loss: 88.5991\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.3527 - val_loss: 88.4447\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.2424 - val_loss: 86.8084\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6461 - val_loss: 87.2649\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6934 - val_loss: 88.6515\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9112 - val_loss: 88.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5947 - val_loss: 88.1026\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3315 - val_loss: 88.1890\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3058 - val_loss: 88.1332\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2962 - val_loss: 90.7102\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2545 - val_loss: 88.9525\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1431 - val_loss: 89.0317\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1871 - val_loss: 87.9488\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1351 - val_loss: 87.0926\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3588 - val_loss: 89.0635\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3939 - val_loss: 87.2275\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4792 - val_loss: 87.8522\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.2422 - val_loss: 95.9562\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.1643 - val_loss: 91.5522\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.5239 - val_loss: 85.2366\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 5.4180 - val_loss: 88.3321\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 7.2972 - val_loss: 117.7655\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 24.4665 - val_loss: 101.5427\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 13.8394 - val_loss: 104.3600\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 14.8797 - val_loss: 89.6950\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 27.0268 - val_loss: 87.7006\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.6257 - val_loss: 87.2480\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 8.2515 - val_loss: 89.9385\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.4479 - val_loss: 86.9250\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.6176 - val_loss: 88.0677\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.1949 - val_loss: 83.4547\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.1927 - val_loss: 90.3149\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.1666 - val_loss: 88.4906\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7550 - val_loss: 87.3062\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.4908 - val_loss: 87.0219\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4380 - val_loss: 85.9354\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2759 - val_loss: 87.2503\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3008 - val_loss: 85.6929\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2077 - val_loss: 86.6112\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2694 - val_loss: 85.5273\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7333 - val_loss: 89.2368\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9131 - val_loss: 89.2351\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.4960 - val_loss: 88.5976\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6084 - val_loss: 86.8914\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3674 - val_loss: 86.5725\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5184 - val_loss: 87.9953\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7223 - val_loss: 86.8018\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4060 - val_loss: 87.9090\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5642 - val_loss: 91.0570\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8112 - val_loss: 86.2380\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 4.3564 - val_loss: 91.7251\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 6.3413 - val_loss: 103.1287\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.8952 - val_loss: 89.8360\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 4.0086 - val_loss: 87.1644\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.5684 - val_loss: 97.4302\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 4.8162 - val_loss: 84.2309\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.4736 - val_loss: 89.9869\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 3.1075 - val_loss: 88.8731\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8973 - val_loss: 87.1451\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.9856 - val_loss: 90.3897\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 6.2284 - val_loss: 87.6726\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 5.5675 - val_loss: 95.4566\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 10.1676 - val_loss: 88.5381\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 7.9476 - val_loss: 103.7408\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 5.0376 - val_loss: 88.0758\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 4.7025 - val_loss: 89.1812\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 5.9829 - val_loss: 91.8640\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 6.0654 - val_loss: 92.4526\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 6.4281 - val_loss: 91.4180\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.6813 - val_loss: 87.6089\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9426 - val_loss: 86.1162\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.4649 - val_loss: 85.2074\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8393 - val_loss: 96.4321\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.5593 - val_loss: 89.4222\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.1910 - val_loss: 88.6362\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.7912 - val_loss: 88.0719\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 2.0830 - val_loss: 89.1500\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.9452 - val_loss: 94.0439\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.8594 - val_loss: 84.7497\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.0988 - val_loss: 87.0442\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.1694 - val_loss: 86.4102\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.7329 - val_loss: 85.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.7431 - val_loss: 86.7336\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.1562 - val_loss: 91.4982\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.6159 - val_loss: 85.1723\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 7.1542 - val_loss: 89.7860\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 6.1519 - val_loss: 85.9386\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.3985 - val_loss: 89.8226\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 11.0393 - val_loss: 85.6498\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 4.8808 - val_loss: 89.5940\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.9454 - val_loss: 93.5025\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.9788 - val_loss: 84.7049\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.2926 - val_loss: 85.4545\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.3781 - val_loss: 84.4072\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.5309 - val_loss: 86.6546\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.2928 - val_loss: 85.7444\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.8559 - val_loss: 85.2336\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5588 - val_loss: 89.4831\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.1429 - val_loss: 87.4924\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.2560 - val_loss: 84.7973\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.5508 - val_loss: 88.0351\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.7119 - val_loss: 86.6388\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.2022 - val_loss: 85.1997\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.9389 - val_loss: 87.1744\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.9968 - val_loss: 86.5378\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.7642 - val_loss: 87.3284\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0517 - val_loss: 91.1678\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 3.2115 - val_loss: 89.0972\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.1835 - val_loss: 87.5163\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 4.4825 - val_loss: 96.2146\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 5.9556 - val_loss: 92.9058\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.9631 - val_loss: 88.3844\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.4722 - val_loss: 87.1531\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 2.2712 - val_loss: 87.7019\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.1879 - val_loss: 93.1168\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.5051 - val_loss: 85.6322\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1623 - val_loss: 84.8902\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7193 - val_loss: 88.2746\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6482 - val_loss: 85.8139\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.7490 - val_loss: 87.7030\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.6665 - val_loss: 85.8446\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.3039 - val_loss: 85.7917\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.6298 - val_loss: 89.1741\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2490 - val_loss: 84.9168\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.4503 - val_loss: 89.6098\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.2701 - val_loss: 89.6221\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.9385 - val_loss: 86.0103\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.4138 - val_loss: 88.6847\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1352 - val_loss: 85.1798\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5762 - val_loss: 95.9608\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.2986 - val_loss: 89.2554\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.4896 - val_loss: 89.8573\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.5050 - val_loss: 101.1839\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 6.7016 - val_loss: 87.3823\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.3505 - val_loss: 91.6431\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.5642 - val_loss: 86.2014\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 5.2230 - val_loss: 85.1628\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.1502 - val_loss: 102.8766\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 5.7230 - val_loss: 83.9985\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.6809 - val_loss: 95.9898\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 6.1993 - val_loss: 86.6626\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.7168 - val_loss: 86.4216\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0930 - val_loss: 89.0225\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7030 - val_loss: 86.9462\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.1361 - val_loss: 87.3423\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7533 - val_loss: 87.9732\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1512 - val_loss: 88.8132\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.8746 - val_loss: 86.6458\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.6258 - val_loss: 87.1567\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4118 - val_loss: 86.5694\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2539 - val_loss: 86.6345\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5119 - val_loss: 84.9441\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4679 - val_loss: 86.8265\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3140 - val_loss: 85.9560\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2716 - val_loss: 85.3590\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.3193 - val_loss: 88.2471\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7252 - val_loss: 84.7706\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.3717 - val_loss: 87.1948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 4.7278 - val_loss: 98.9475\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 21.4891 - val_loss: 123.0294\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 16.3750 - val_loss: 93.0923\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 9.7997 - val_loss: 97.2692\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.8249 - val_loss: 91.4153\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8730 - val_loss: 85.9165\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9719 - val_loss: 86.7869\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6628 - val_loss: 86.1226\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4823 - val_loss: 85.0539\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3290 - val_loss: 85.0437\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2603 - val_loss: 86.2198\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1604 - val_loss: 86.0700\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1341 - val_loss: 85.8908\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0646 - val_loss: 85.0193\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0649 - val_loss: 85.2613\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0511 - val_loss: 85.2389\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0354 - val_loss: 85.1381\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0806 - val_loss: 85.0789\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1154 - val_loss: 85.0807\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1124 - val_loss: 85.8943\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1802 - val_loss: 86.1082\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1852 - val_loss: 84.7982\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2791 - val_loss: 87.5094\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3645 - val_loss: 86.5909\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7696 - val_loss: 85.3080\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1451 - val_loss: 84.9233\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2985 - val_loss: 86.7373\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 18.9388 - val_loss: 146.3338\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 13.0945 - val_loss: 93.1926\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.8814 - val_loss: 90.4882\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.8345 - val_loss: 88.3363\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0278 - val_loss: 87.0099\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6739 - val_loss: 86.5215\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5073 - val_loss: 86.0247\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5063 - val_loss: 87.4610\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.5450 - val_loss: 85.3104\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8945 - val_loss: 85.9843\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4433 - val_loss: 87.5264\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2976 - val_loss: 87.4002\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2451 - val_loss: 85.9742\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2082 - val_loss: 86.3520\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1693 - val_loss: 85.6660\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2895 - val_loss: 86.3839\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4447 - val_loss: 87.9449\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4717 - val_loss: 87.4191\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.8023 - val_loss: 87.2349\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.6590 - val_loss: 86.5661\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.0289 - val_loss: 87.7820\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.7333 - val_loss: 87.6237\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.6306 - val_loss: 89.0761\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.6047 - val_loss: 87.7318\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.0116 - val_loss: 90.4851\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.1481 - val_loss: 87.5988\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.3157 - val_loss: 85.5765\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9809 - val_loss: 85.7649\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.8912 - val_loss: 86.8793\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9868 - val_loss: 84.4105\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.6861 - val_loss: 93.0556\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.9838 - val_loss: 90.4401\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 11.9270 - val_loss: 90.3737\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.4744 - val_loss: 88.8490\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.6211 - val_loss: 87.5555\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9482 - val_loss: 86.9039\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7352 - val_loss: 87.3869\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4930 - val_loss: 86.1367\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3854 - val_loss: 87.5012\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7482 - val_loss: 84.9151\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.5089 - val_loss: 85.2754\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1817 - val_loss: 86.4958\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1915 - val_loss: 85.4191\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4754 - val_loss: 85.9308\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3631 - val_loss: 85.4437\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4625 - val_loss: 86.4664\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2394 - val_loss: 87.0876\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3286 - val_loss: 86.2239\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3170 - val_loss: 85.5136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4624 - val_loss: 87.3230\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4011 - val_loss: 86.8349\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7999 - val_loss: 86.9179\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.3895 - val_loss: 90.1820\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.3207 - val_loss: 88.5762\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.6659 - val_loss: 94.4553\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.4299 - val_loss: 89.1288\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.7650 - val_loss: 96.9476\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.6281 - val_loss: 95.5582\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.8753 - val_loss: 91.4006\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5273 - val_loss: 88.0207\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0761 - val_loss: 86.1818\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5391 - val_loss: 86.0771\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4533 - val_loss: 86.3039\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4442 - val_loss: 85.5269\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2274 - val_loss: 86.0233\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2534 - val_loss: 86.3219\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4456 - val_loss: 85.0439\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3233 - val_loss: 86.0610\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3260 - val_loss: 88.2723\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.1415 - val_loss: 86.5548\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.6219 - val_loss: 86.0101\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7391 - val_loss: 86.8307\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6806 - val_loss: 85.6728\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.7418 - val_loss: 92.8854\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.3061 - val_loss: 94.4716\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.2663 - val_loss: 89.7725\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.8085 - val_loss: 93.7044\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.4245 - val_loss: 92.4892\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.7965 - val_loss: 88.0960\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.5846 - val_loss: 94.3598\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 4.6560 - val_loss: 97.7760\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.3316 - val_loss: 86.9321\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.4675 - val_loss: 87.6201\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.9747 - val_loss: 87.9948\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1323 - val_loss: 87.2329\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.0012 - val_loss: 86.9899\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4103 - val_loss: 86.9761\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5468 - val_loss: 91.4639\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7888 - val_loss: 85.7751\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9021 - val_loss: 86.8296\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9132 - val_loss: 86.2606\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5168 - val_loss: 86.0989\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3747 - val_loss: 87.3718\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3509 - val_loss: 88.4072\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8658 - val_loss: 87.4922\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2047 - val_loss: 87.5695\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.2523 - val_loss: 90.0755\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.6220 - val_loss: 86.6146\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2436 - val_loss: 85.1450\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8473 - val_loss: 85.7102\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.6678 - val_loss: 85.0269\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.6698 - val_loss: 86.7056\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5059 - val_loss: 87.4329\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4129 - val_loss: 85.1708\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2950 - val_loss: 86.3832\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3070 - val_loss: 86.0203\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7964 - val_loss: 88.2407\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2010 - val_loss: 87.9065\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.1313 - val_loss: 87.0722\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 6.9018 - val_loss: 100.1073\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 6.9660 - val_loss: 88.9886\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.7827 - val_loss: 91.0698\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.6829 - val_loss: 86.8857\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8209 - val_loss: 86.9053\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5793 - val_loss: 87.6383\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.2293 - val_loss: 85.3265\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.1957 - val_loss: 87.9770\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5633 - val_loss: 85.2768\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3087 - val_loss: 85.2451\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2390 - val_loss: 85.1026\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1844 - val_loss: 85.7684\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0911 - val_loss: 85.3905\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0846 - val_loss: 85.5003\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0843 - val_loss: 85.7463\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0452 - val_loss: 86.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0381 - val_loss: 85.5449\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0713 - val_loss: 85.5033\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4326 - val_loss: 84.5193\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5476 - val_loss: 88.7703\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.3277 - val_loss: 93.5886\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 3.6917 - val_loss: 91.5571\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 5.3203 - val_loss: 89.6090\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 11.5930 - val_loss: 87.2407\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 12.7609 - val_loss: 94.3403\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 7.1639 - val_loss: 91.6373\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.2086 - val_loss: 86.7344\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.6225 - val_loss: 91.0827\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.9388 - val_loss: 86.1850\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7732 - val_loss: 85.7628\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6723 - val_loss: 88.2592\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7953 - val_loss: 86.8396\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4824 - val_loss: 85.2127\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2716 - val_loss: 84.7573\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1303 - val_loss: 85.3428\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0727 - val_loss: 85.1731\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0773 - val_loss: 86.3729\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1391 - val_loss: 86.2180\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1249 - val_loss: 85.6178\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1089 - val_loss: 85.2197\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2119 - val_loss: 85.6402\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3451 - val_loss: 85.4208\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4460 - val_loss: 89.0968\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5107 - val_loss: 85.3584\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7648 - val_loss: 84.4449\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6790 - val_loss: 84.6912\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7598 - val_loss: 84.7782\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.3106 - val_loss: 84.9030\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8276 - val_loss: 87.1434\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6385 - val_loss: 83.8696\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6208 - val_loss: 86.2868\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.1078 - val_loss: 84.8878\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.9757 - val_loss: 86.3830\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 2.6873 - val_loss: 84.9870\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.9601 - val_loss: 85.5588\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.7398 - val_loss: 85.0299\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.3275 - val_loss: 86.6729\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.9368 - val_loss: 83.6583\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.7201 - val_loss: 86.7196\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.2671 - val_loss: 89.3125\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.4043 - val_loss: 85.7610\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9884 - val_loss: 84.7478\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5481 - val_loss: 86.8034\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3811 - val_loss: 84.5328\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1749 - val_loss: 86.7797\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6270 - val_loss: 84.9483\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5870 - val_loss: 84.1438\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4361 - val_loss: 85.1415\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3851 - val_loss: 84.8966\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3295 - val_loss: 85.4998\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3177 - val_loss: 86.2702\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.2368 - val_loss: 85.7028\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.3625 - val_loss: 85.7055\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.9578 - val_loss: 85.2554\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.9444 - val_loss: 89.2900\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.4549 - val_loss: 85.6516\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0395 - val_loss: 86.1406\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.6387 - val_loss: 89.0783\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.8390 - val_loss: 86.5239\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.9575 - val_loss: 89.9168\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.8016 - val_loss: 84.1709\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.3390 - val_loss: 91.0608\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.3555 - val_loss: 89.5563\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.1010 - val_loss: 91.5783\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9238 - val_loss: 84.4786\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7038 - val_loss: 85.0634\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.9280 - val_loss: 85.2249\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6615 - val_loss: 85.4221\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6019 - val_loss: 85.7830\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7135 - val_loss: 85.0043\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5074 - val_loss: 85.1740\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3006 - val_loss: 85.6590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1894 - val_loss: 85.6555\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1636 - val_loss: 86.1985\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1480 - val_loss: 85.7666\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1279 - val_loss: 85.6426\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0720 - val_loss: 85.0885\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2044 - val_loss: 86.4763\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2994 - val_loss: 87.7039\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.7170 - val_loss: 85.4885\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7026 - val_loss: 84.5725\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.1236 - val_loss: 86.3249\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.2380 - val_loss: 87.1787\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.8450 - val_loss: 86.6729\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.6390 - val_loss: 86.5585\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.7624 - val_loss: 90.1923\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 3.5757 - val_loss: 87.7127\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.9778 - val_loss: 86.8389\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.7350 - val_loss: 85.6493\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 2.4444 - val_loss: 88.9398\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 4.0832 - val_loss: 84.9080\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.7651 - val_loss: 86.2957\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0129 - val_loss: 87.7611\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7196 - val_loss: 87.5255\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 1.1114 - val_loss: 87.8668\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 3.8603 - val_loss: 88.6856\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 5.4521 - val_loss: 92.5521\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.0300 - val_loss: 89.9961\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.8299 - val_loss: 85.2046\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.2002 - val_loss: 85.4106\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.5585 - val_loss: 86.8062\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7458 - val_loss: 85.8307\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.4011 - val_loss: 85.6920\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.4999 - val_loss: 85.6215\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2948 - val_loss: 85.5239\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.2165 - val_loss: 85.3648\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1392 - val_loss: 85.8074\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1388 - val_loss: 85.9123\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1434 - val_loss: 85.3773\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.6683 - val_loss: 84.8498\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.3179 - val_loss: 85.7777\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.8964 - val_loss: 87.3029\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.3086 - val_loss: 86.4741\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.2654 - val_loss: 85.7781\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.5585 - val_loss: 94.1478\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.8811 - val_loss: 86.1553\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.6836 - val_loss: 85.3801\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.3050 - val_loss: 86.3337\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.4368 - val_loss: 85.2508\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.8817 - val_loss: 84.4362\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.5524 - val_loss: 84.4415\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3667 - val_loss: 85.4117\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.3313 - val_loss: 85.0260\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.1932 - val_loss: 85.0427\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.1917 - val_loss: 84.9721\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1736 - val_loss: 84.9379\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1350 - val_loss: 85.2938\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0836 - val_loss: 85.3175\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0599 - val_loss: 85.1712\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0526 - val_loss: 85.2227\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0791 - val_loss: 85.2593\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0956 - val_loss: 85.3459\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1178 - val_loss: 85.4968\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1975 - val_loss: 85.6367\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.7082 - val_loss: 84.8130\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 6.8186 - val_loss: 83.9038\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.5340 - val_loss: 90.2818\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.3416 - val_loss: 89.3887\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.9540 - val_loss: 85.9569\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1317 - val_loss: 84.3221\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6023 - val_loss: 84.8393\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3490 - val_loss: 85.0720\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1992 - val_loss: 85.4625\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2790 - val_loss: 86.4031\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2093 - val_loss: 84.9735\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1461 - val_loss: 85.6682\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1777 - val_loss: 85.2395\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1521 - val_loss: 85.8524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1998 - val_loss: 84.5952\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3806 - val_loss: 85.3430\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5245 - val_loss: 85.9019\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.2465 - val_loss: 85.7009\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.8842 - val_loss: 84.8882\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5229 - val_loss: 85.3296\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5120 - val_loss: 85.2547\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.6279 - val_loss: 85.2589\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2707 - val_loss: 85.7166\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.9564 - val_loss: 85.5320\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.6145 - val_loss: 85.4570\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9293 - val_loss: 84.0309\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.9453 - val_loss: 86.2784\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.5339 - val_loss: 86.5242\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.7558 - val_loss: 91.5462\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.3048 - val_loss: 86.9358\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 5.8177 - val_loss: 84.9406\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.7436 - val_loss: 84.1755\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.9330 - val_loss: 87.2821\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2728 - val_loss: 87.8913\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0466 - val_loss: 85.5523\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5489 - val_loss: 84.7561\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3115 - val_loss: 85.7041\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2684 - val_loss: 85.9079\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1504 - val_loss: 85.5239\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1202 - val_loss: 85.6708\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0672 - val_loss: 85.4090\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0572 - val_loss: 85.4891\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0814 - val_loss: 85.4422\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1695 - val_loss: 85.0490\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1240 - val_loss: 85.2597\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0776 - val_loss: 85.8119\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0847 - val_loss: 85.5836\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1553 - val_loss: 85.6476\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2624 - val_loss: 85.4895\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1317 - val_loss: 85.2252\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2194 - val_loss: 85.3874\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.0689 - val_loss: 117.2133\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 9.0359 - val_loss: 88.6494\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.3681 - val_loss: 92.8440\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.9096 - val_loss: 87.2674\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9616 - val_loss: 86.6137\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8189 - val_loss: 84.8881\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4486 - val_loss: 85.2117\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2658 - val_loss: 84.6697\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4543 - val_loss: 84.4513\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4876 - val_loss: 84.0483\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3559 - val_loss: 84.8507\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2388 - val_loss: 84.6342\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1418 - val_loss: 84.5813\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1057 - val_loss: 84.5933\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0678 - val_loss: 84.5843\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0531 - val_loss: 85.0378\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2219 - val_loss: 85.8047\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2317 - val_loss: 84.5298\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5962 - val_loss: 85.2274\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4410 - val_loss: 84.3757\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5112 - val_loss: 83.9184\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5536 - val_loss: 83.4836\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9605 - val_loss: 89.6710\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2964 - val_loss: 85.9807\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.5121 - val_loss: 88.6655\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2649 - val_loss: 84.6226\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0352 - val_loss: 84.5119\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.1757 - val_loss: 84.8384\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9880 - val_loss: 86.4157\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5766 - val_loss: 86.7222\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.8158 - val_loss: 84.6081\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0978 - val_loss: 83.7082\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8302 - val_loss: 84.2484\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5275 - val_loss: 84.9594\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4432 - val_loss: 84.1643\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3419 - val_loss: 84.2393\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2606 - val_loss: 84.5103\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3263 - val_loss: 84.3943\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3627 - val_loss: 85.4507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5049 - val_loss: 85.5678\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7462 - val_loss: 85.0480\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.1605 - val_loss: 83.4136\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.3472 - val_loss: 84.9123\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.0061 - val_loss: 85.1810\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.5170 - val_loss: 84.3957\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.4630 - val_loss: 86.0731\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.1619 - val_loss: 84.6653\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6669 - val_loss: 83.8026\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5078 - val_loss: 85.5108\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3639 - val_loss: 84.3374\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2203 - val_loss: 84.1715\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1206 - val_loss: 84.6750\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0728 - val_loss: 84.2892\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0965 - val_loss: 84.8797\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1788 - val_loss: 84.9349\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3797 - val_loss: 84.3301\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3891 - val_loss: 84.5022\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3334 - val_loss: 85.2963\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2381 - val_loss: 84.2346\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4050 - val_loss: 84.4746\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4700 - val_loss: 84.4899\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.4483 - val_loss: 87.3494\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.2736 - val_loss: 87.9167\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 7.2493 - val_loss: 89.3582\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 8.8789 - val_loss: 84.2380\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.4422 - val_loss: 85.7355\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.3437 - val_loss: 83.5688\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.8353 - val_loss: 83.3683\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4510 - val_loss: 84.5255\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.6404 - val_loss: 87.0603\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4493 - val_loss: 83.8506\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2038 - val_loss: 84.6848\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3837 - val_loss: 84.0858\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2925 - val_loss: 84.8493\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1577 - val_loss: 84.2653\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1278 - val_loss: 84.0970\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1265 - val_loss: 85.0268\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1687 - val_loss: 84.5670\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3026 - val_loss: 84.9043\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2038 - val_loss: 85.0863\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1112 - val_loss: 84.4730\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.1260 - val_loss: 84.3575\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1257 - val_loss: 85.0460\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0932 - val_loss: 84.2058\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0952 - val_loss: 84.9538\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2428 - val_loss: 84.1460\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3736 - val_loss: 84.4587\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5779 - val_loss: 85.9543\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.3932 - val_loss: 87.2133\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 6.0166 - val_loss: 91.1029\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 3.9669 - val_loss: 91.8702\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.5337 - val_loss: 90.0022\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.5685 - val_loss: 86.1895\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8847 - val_loss: 87.7223\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.0561 - val_loss: 85.8974\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.6388 - val_loss: 85.1043\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3138 - val_loss: 84.9371\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1923 - val_loss: 84.3920\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1935 - val_loss: 84.8779\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5420 - val_loss: 85.7142\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.8353 - val_loss: 84.2040\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3712 - val_loss: 85.1111\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.4573 - val_loss: 85.4229\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1763 - val_loss: 84.5191\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1278 - val_loss: 84.7322\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1449 - val_loss: 84.1154\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0995 - val_loss: 85.1097\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0771 - val_loss: 84.4339\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0678 - val_loss: 84.8412\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0542 - val_loss: 84.7074\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0370 - val_loss: 84.9871\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.0999 - val_loss: 84.9169\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0641 - val_loss: 84.9621\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.1403 - val_loss: 83.9086\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3839 - val_loss: 85.3257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.0719 - val_loss: 88.1944\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.0142 - val_loss: 89.9665\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.1510 - val_loss: 87.0693\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 3.3004 - val_loss: 88.3809\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 4.1494 - val_loss: 88.6056\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.6930 - val_loss: 84.8090\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.5383 - val_loss: 84.3473\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.6317 - val_loss: 84.5822\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.2354 - val_loss: 85.3362\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.1264 - val_loss: 84.2533\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.4317 - val_loss: 85.0617\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3129 - val_loss: 84.6328\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2916 - val_loss: 84.0317\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2257 - val_loss: 84.3770\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1415 - val_loss: 84.4951\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0903 - val_loss: 84.2761\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2384 - val_loss: 84.6328\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3060 - val_loss: 84.4609\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6854 - val_loss: 84.8845\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4709 - val_loss: 84.6252\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2318 - val_loss: 84.0319\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3342 - val_loss: 84.4130\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3023 - val_loss: 84.2205\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7043 - val_loss: 85.1246\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6498 - val_loss: 85.1619\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4035 - val_loss: 85.1098\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3823 - val_loss: 84.7547\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.7132 - val_loss: 86.2598\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 2.6410 - val_loss: 84.8433\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1559 - val_loss: 86.8000\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7604 - val_loss: 87.8576\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.8340 - val_loss: 85.7339\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.3352 - val_loss: 85.0125\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9665 - val_loss: 83.7262\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9065 - val_loss: 85.0645\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7213 - val_loss: 84.8515\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0675 - val_loss: 86.9028\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6144 - val_loss: 84.5543\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6797 - val_loss: 84.2988\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4792 - val_loss: 85.4268\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2929 - val_loss: 84.7946\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1494 - val_loss: 85.2184\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0995 - val_loss: 84.7244\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0988 - val_loss: 84.2886\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3845 - val_loss: 85.4481\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.4139 - val_loss: 86.8082\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 6.6540 - val_loss: 88.1912\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.6088 - val_loss: 85.3845\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.3559 - val_loss: 85.3760\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.7226 - val_loss: 86.6870\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5207 - val_loss: 86.1714\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.8891 - val_loss: 85.5548\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7965 - val_loss: 85.5645\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5254 - val_loss: 84.8085\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3037 - val_loss: 84.8026\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1363 - val_loss: 84.7425\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1139 - val_loss: 85.4551\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0937 - val_loss: 85.0506\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0452 - val_loss: 84.7926\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0372 - val_loss: 84.7993\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0487 - val_loss: 85.0654\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0426 - val_loss: 84.8341\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0308 - val_loss: 85.1834\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0488 - val_loss: 84.5450\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0288 - val_loss: 84.6243\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0204 - val_loss: 84.8419\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0519 - val_loss: 84.7452\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3210 - val_loss: 88.1438\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6388 - val_loss: 85.9852\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.4458 - val_loss: 89.4312\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.1695 - val_loss: 83.4923\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.6034 - val_loss: 84.0805\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.3703 - val_loss: 86.3572\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.8163 - val_loss: 87.6300\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.3988 - val_loss: 83.5660\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7762 - val_loss: 85.5046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4829 - val_loss: 86.2192\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4003 - val_loss: 84.6208\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4325 - val_loss: 84.5220\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6463 - val_loss: 86.2402\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4259 - val_loss: 84.3919\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2374 - val_loss: 84.4919\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1152 - val_loss: 84.9880\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3800 - val_loss: 84.6942\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4630 - val_loss: 84.4786\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8498 - val_loss: 84.1125\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7446 - val_loss: 84.6023\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7029 - val_loss: 86.3276\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8592 - val_loss: 85.4988\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.8299 - val_loss: 83.7097\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3996 - val_loss: 85.1471\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6586 - val_loss: 85.0581\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.8808 - val_loss: 83.8482\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6242 - val_loss: 85.9639\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3768 - val_loss: 85.7109\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.7654 - val_loss: 84.8326\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.6544 - val_loss: 85.1581\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4238 - val_loss: 83.9123\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5031 - val_loss: 83.9953\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4831 - val_loss: 84.0827\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3228 - val_loss: 84.3308\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3799 - val_loss: 84.2735\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6442 - val_loss: 85.9449\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3834 - val_loss: 85.3462\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6476 - val_loss: 83.1207\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.2690 - val_loss: 91.2863\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 6.1065 - val_loss: 86.1459\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.1163 - val_loss: 84.9614\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.3274 - val_loss: 85.4201\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.6281 - val_loss: 86.0762\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4659 - val_loss: 84.6292\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3322 - val_loss: 84.5629\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2085 - val_loss: 85.1012\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3858 - val_loss: 84.8167\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2887 - val_loss: 84.9762\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1896 - val_loss: 84.9460\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1950 - val_loss: 83.8928\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4636 - val_loss: 84.4085\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6245 - val_loss: 84.9328\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2342 - val_loss: 84.4499\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1359 - val_loss: 84.2284\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0961 - val_loss: 84.7238\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0848 - val_loss: 84.5339\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0452 - val_loss: 84.6725\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0433 - val_loss: 84.5342\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0420 - val_loss: 84.6478\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0824 - val_loss: 84.7548\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0765 - val_loss: 84.2090\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0546 - val_loss: 84.5621\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0423 - val_loss: 85.0338\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2256 - val_loss: 84.9182\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2727 - val_loss: 86.1951\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.9212 - val_loss: 84.6113\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8069 - val_loss: 90.0417\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.5056 - val_loss: 84.7285\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.3158 - val_loss: 84.0765\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7287 - val_loss: 83.8425\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4645 - val_loss: 84.2358\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4539 - val_loss: 84.4341\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3194 - val_loss: 84.0733\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2793 - val_loss: 83.4248\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1730 - val_loss: 83.8715\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1861 - val_loss: 83.8454\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4213 - val_loss: 84.7956\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.8696 - val_loss: 89.2185\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.3444 - val_loss: 85.5229\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9921 - val_loss: 84.1214\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5393 - val_loss: 83.4701\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8496 - val_loss: 84.7400\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3566 - val_loss: 85.7056\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3747 - val_loss: 85.1944\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3949 - val_loss: 84.2924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4868 - val_loss: 84.3744\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2218 - val_loss: 84.3947\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1731 - val_loss: 84.8080\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2193 - val_loss: 85.8061\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4666 - val_loss: 85.3508\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3042 - val_loss: 84.9480\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4988 - val_loss: 85.8197\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.0846 - val_loss: 83.6112\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6956 - val_loss: 83.9890\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3139 - val_loss: 84.5875\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1861 - val_loss: 84.4559\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2554 - val_loss: 84.8932\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.2941 - val_loss: 88.9345\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.3309 - val_loss: 85.0408\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2867 - val_loss: 83.9431\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2189 - val_loss: 83.7489\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.8299 - val_loss: 85.6745\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.3853 - val_loss: 86.6123\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.2162 - val_loss: 83.4498\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7483 - val_loss: 84.7838\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.6102 - val_loss: 84.4713\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7360 - val_loss: 84.2123\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4398 - val_loss: 84.2274\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2504 - val_loss: 83.9830\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1477 - val_loss: 84.0069\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1579 - val_loss: 83.9848\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1721 - val_loss: 83.8977\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1923 - val_loss: 83.4761\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5513 - val_loss: 84.5365\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7739 - val_loss: 83.6494\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7795 - val_loss: 84.4406\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.4162 - val_loss: 83.4624\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.3150 - val_loss: 83.8679\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6362 - val_loss: 84.5396\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5015 - val_loss: 84.2749\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3354 - val_loss: 83.7797\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.2809 - val_loss: 83.7081\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4581 - val_loss: 84.2889\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7415 - val_loss: 84.1931\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8644 - val_loss: 84.5760\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.0458 - val_loss: 83.3718\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2822 - val_loss: 85.3782\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7027 - val_loss: 83.1413\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.7610 - val_loss: 84.8075\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5684 - val_loss: 84.7121\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7581 - val_loss: 82.0187\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3935 - val_loss: 84.9040\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4512 - val_loss: 83.7383\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3947 - val_loss: 83.4771\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3406 - val_loss: 82.7445\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5103 - val_loss: 86.2784\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.6477 - val_loss: 84.0968\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.1746 - val_loss: 87.9594\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.7507 - val_loss: 84.7449\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.4372 - val_loss: 83.6142\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.1704 - val_loss: 83.0768\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5275 - val_loss: 82.5132\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2518 - val_loss: 82.8860\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1980 - val_loss: 83.3683\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3124 - val_loss: 83.9112\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1612 - val_loss: 83.1347\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1653 - val_loss: 82.7766\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1229 - val_loss: 83.4079\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3901 - val_loss: 84.1677\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4249 - val_loss: 83.0732\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3491 - val_loss: 84.2495\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.0748 - val_loss: 84.8286\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.0604 - val_loss: 83.5928\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.9955 - val_loss: 84.5000\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8091 - val_loss: 83.9077\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.9472 - val_loss: 82.7269\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1115 - val_loss: 85.2066\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6055 - val_loss: 83.1939\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6165 - val_loss: 85.8520\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4019 - val_loss: 84.2125\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2391 - val_loss: 84.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7475 - val_loss: 85.1205\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8290 - val_loss: 83.9994\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6205 - val_loss: 85.4885\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2473 - val_loss: 83.8239\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4195 - val_loss: 83.5582\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2628 - val_loss: 83.2753\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1438 - val_loss: 84.1439\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0734 - val_loss: 83.8220\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0952 - val_loss: 83.7925\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0764 - val_loss: 83.9007\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1865 - val_loss: 84.3641\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3763 - val_loss: 83.1575\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3637 - val_loss: 84.4594\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5298 - val_loss: 83.6558\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6714 - val_loss: 83.5588\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.8159 - val_loss: 85.2599\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.6920 - val_loss: 84.1278\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.4330 - val_loss: 83.3945\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8926 - val_loss: 84.3941\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7207 - val_loss: 84.0662\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4449 - val_loss: 84.2945\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 1.0959 - val_loss: 85.9513\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.1117 - val_loss: 86.2379\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.3394 - val_loss: 85.2707\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.1046 - val_loss: 84.1814\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2359 - val_loss: 83.4459\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4790 - val_loss: 83.3110\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3966 - val_loss: 83.9147\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3316 - val_loss: 84.0540\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2693 - val_loss: 83.4147\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1690 - val_loss: 83.6318\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1320 - val_loss: 83.9003\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0586 - val_loss: 83.8022\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0664 - val_loss: 83.4302\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0465 - val_loss: 83.4324\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0847 - val_loss: 83.6868\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0849 - val_loss: 83.6937\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5941 - val_loss: 84.7195\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6133 - val_loss: 83.2662\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5298 - val_loss: 84.0290\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5357 - val_loss: 86.8276\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.1921 - val_loss: 85.2517\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.2085 - val_loss: 83.8990\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5093 - val_loss: 83.3733\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6401 - val_loss: 84.8725\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.8487 - val_loss: 88.6652\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.4984 - val_loss: 84.4026\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.4950 - val_loss: 83.5846\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.0062 - val_loss: 82.8298\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5234 - val_loss: 83.9052\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4569 - val_loss: 82.9803\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1876 - val_loss: 83.8812\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1750 - val_loss: 82.9059\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1421 - val_loss: 83.4152\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0736 - val_loss: 83.0858\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0674 - val_loss: 83.1941\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0930 - val_loss: 83.3153\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1181 - val_loss: 83.5631\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0621 - val_loss: 83.7086\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0486 - val_loss: 83.7212\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0300 - val_loss: 83.4071\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0349 - val_loss: 83.7512\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0383 - val_loss: 83.5344\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0411 - val_loss: 83.4236\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1274 - val_loss: 83.5750\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1857 - val_loss: 83.5179\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1519 - val_loss: 83.7693\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5308 - val_loss: 83.0452\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5789 - val_loss: 83.6747\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.2862 - val_loss: 87.4494\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.7805 - val_loss: 86.3360\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.0947 - val_loss: 83.7485\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.2359 - val_loss: 84.7453\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.3415 - val_loss: 84.8311\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.7511 - val_loss: 84.5471\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.4800 - val_loss: 82.9085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6511 - val_loss: 84.2014\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4601 - val_loss: 83.7042\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7191 - val_loss: 84.8389\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8804 - val_loss: 83.8804\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7173 - val_loss: 84.5346\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7786 - val_loss: 85.0496\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7523 - val_loss: 84.0191\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.2964 - val_loss: 84.9100\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.2390 - val_loss: 85.1402\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8181 - val_loss: 85.1302\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9407 - val_loss: 84.5803\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.7801 - val_loss: 83.2967\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 40us/step\n",
      "81.64734741210937\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "    \n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "        \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "\n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts: \n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "        \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨볼루션 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 716us/step - loss: 12946.2000 - val_loss: 1828.5113\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1492.0726 - val_loss: 1125.4913\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 1074.8605 - val_loss: 882.5392\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 802.9924 - val_loss: 624.7470\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 515.6336 - val_loss: 451.1064\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 337.7659 - val_loss: 301.8321\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 289.7249 - val_loss: 291.7713\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 270.1249 - val_loss: 296.3061\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 252.7722 - val_loss: 260.2313\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 237.1322 - val_loss: 269.4253\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 225.1202 - val_loss: 252.0752\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 214.8396 - val_loss: 238.6746\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 201.0069 - val_loss: 244.4025\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 197.3382 - val_loss: 226.2861\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 187.2338 - val_loss: 218.9864\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 185.5130 - val_loss: 217.5401\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 182.3469 - val_loss: 213.6267\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 174.2864 - val_loss: 212.9271\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 174.5820 - val_loss: 229.6265\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 175.0572 - val_loss: 207.8495\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 167.6153 - val_loss: 223.1237\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 162.3169 - val_loss: 222.5416\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 171.8990 - val_loss: 202.6613\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 167.9791 - val_loss: 217.0293\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 162.7766 - val_loss: 220.6073\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 157.2387 - val_loss: 202.1637\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 159.2591 - val_loss: 196.0455\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 152.2525 - val_loss: 193.1615\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 173.1082 - val_loss: 206.4441\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 156.9591 - val_loss: 216.2100\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 149.6695 - val_loss: 210.7145\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 143.1511 - val_loss: 195.5050\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 145.9890 - val_loss: 202.7218\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 144.6945 - val_loss: 187.4142\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 139.0558 - val_loss: 189.6289\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 135.7083 - val_loss: 190.4091\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 138.0460 - val_loss: 197.4413\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 158.0928 - val_loss: 194.3626\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 139.3754 - val_loss: 183.9529\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 128.0597 - val_loss: 184.3972\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 137.7226 - val_loss: 217.0319\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 128.5461 - val_loss: 181.6215\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 124.2085 - val_loss: 184.7390\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 122.5232 - val_loss: 188.4247\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 136.6462 - val_loss: 187.2606\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 121.6757 - val_loss: 213.6682\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 134.5373 - val_loss: 183.2267\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 122.1855 - val_loss: 177.8187\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 121.4819 - val_loss: 197.3594\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 133.4433 - val_loss: 210.8910\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 144.8502 - val_loss: 175.1288\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 114.4117 - val_loss: 174.0029\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 117.9651 - val_loss: 179.8081\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 136.1529 - val_loss: 178.9394\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 108.9872 - val_loss: 173.7496\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 111.2956 - val_loss: 172.7932\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 104.7684 - val_loss: 192.1154\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 106.0694 - val_loss: 172.5444\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 103.6983 - val_loss: 181.7249\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 107.0533 - val_loss: 171.4173\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 113.1078 - val_loss: 170.4466\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 104.4646 - val_loss: 170.1092\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 99.0143 - val_loss: 170.1115\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 99.4421 - val_loss: 171.3329\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 97.0566 - val_loss: 207.1329\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 106.6804 - val_loss: 169.7099\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 109.0643 - val_loss: 201.3948\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 105.3964 - val_loss: 223.9343\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 98.6696 - val_loss: 186.2857\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 92.3662 - val_loss: 168.9747\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 92.7781 - val_loss: 197.8195\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 88.6360 - val_loss: 173.7189\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 91.3433 - val_loss: 173.9674\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 94.9339 - val_loss: 199.5883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 88.9631 - val_loss: 222.5583\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 89.8289 - val_loss: 173.1745\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 92.4083 - val_loss: 169.7945\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 83.2404 - val_loss: 176.8256\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 87.8868 - val_loss: 169.3921\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 79.9549 - val_loss: 169.6697\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 79.0268 - val_loss: 176.9036\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 82.1283 - val_loss: 180.7014\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 77.1573 - val_loss: 171.6368\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 75.9445 - val_loss: 189.3525\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 78.2809 - val_loss: 171.2061\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 75.0367 - val_loss: 179.1989\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 82.6783 - val_loss: 173.8410\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 88.1050 - val_loss: 210.9072\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 81.4956 - val_loss: 170.8608\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 72.4322 - val_loss: 207.4232\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 77.8804 - val_loss: 170.6101\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 72.6657 - val_loss: 171.7706\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 67.9123 - val_loss: 176.9070\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 74.3363 - val_loss: 170.4737\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 71.0593 - val_loss: 176.3833\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 63.4223 - val_loss: 173.6959\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 75.7521 - val_loss: 206.0824\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 65.3391 - val_loss: 199.8016\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 74.4603 - val_loss: 179.1426\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 61.9101 - val_loss: 184.6520\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 64.6663 - val_loss: 174.0392\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 60.1118 - val_loss: 175.5358\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 63.0955 - val_loss: 187.1537\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 66.0563 - val_loss: 174.9214\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 58.1358 - val_loss: 172.7978\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 58.3649 - val_loss: 195.6921\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 56.7936 - val_loss: 174.2307\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 54.8484 - val_loss: 176.7952\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 58.4786 - val_loss: 176.8627\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 55.2730 - val_loss: 181.7694\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 66.2004 - val_loss: 249.2066\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 57.0018 - val_loss: 176.9508\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 56.1571 - val_loss: 179.7093\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 51.2086 - val_loss: 179.9781\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 52.5898 - val_loss: 175.0488\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 51.0830 - val_loss: 183.3864\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 50.7735 - val_loss: 177.1716\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 47.5731 - val_loss: 176.8591\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 51.3919 - val_loss: 181.4185\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 45.1214 - val_loss: 182.7631\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 46.9601 - val_loss: 189.6007\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 43.9777 - val_loss: 178.9467\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 46.8872 - val_loss: 200.8321\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 45.7138 - val_loss: 176.8995\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 48.5172 - val_loss: 190.3786\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 40.7997 - val_loss: 181.6864\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 44.8942 - val_loss: 192.3582\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 45.1331 - val_loss: 186.6335\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 42.9393 - val_loss: 201.7637\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 40.0863 - val_loss: 181.3299\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 39.9611 - val_loss: 197.9940\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 38.9833 - val_loss: 181.4539\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 34.6474 - val_loss: 188.9512\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 36.2476 - val_loss: 183.1392\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 33.0250 - val_loss: 191.2398\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 32.7935 - val_loss: 186.6166\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 31.3895 - val_loss: 183.1621\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 33.3414 - val_loss: 191.9328\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 35.9683 - val_loss: 195.3805\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 35.1555 - val_loss: 187.1453\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 33.9399 - val_loss: 184.7461\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 31.8970 - val_loss: 190.0973\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 29.8173 - val_loss: 188.0514\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 32.6731 - val_loss: 192.5943\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 28.4437 - val_loss: 189.5048\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 30.1984 - val_loss: 189.7147\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 27.1826 - val_loss: 193.3360\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 31.5223 - val_loss: 190.1730\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 97us/step - loss: 27.8678 - val_loss: 192.0362\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 23.8645 - val_loss: 189.9114\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 24.6160 - val_loss: 191.6932\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 26.9705 - val_loss: 205.0794\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 23.0800 - val_loss: 201.5598\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 22.0606 - val_loss: 193.7949\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 21.1375 - val_loss: 201.3014\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 21.0678 - val_loss: 193.0531\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 21.6781 - val_loss: 198.6851\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 22.6748 - val_loss: 202.0305\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 20.9592 - val_loss: 208.3090\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 22.8432 - val_loss: 201.1891\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 20.8098 - val_loss: 202.5222\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 21.2649 - val_loss: 199.1127\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 19.3253 - val_loss: 200.3279\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 19.1430 - val_loss: 200.7941\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 17.0756 - val_loss: 200.6499\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 21.8467 - val_loss: 202.9953\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 18.6550 - val_loss: 212.5441\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 17.6319 - val_loss: 204.3546\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 15.2214 - val_loss: 201.7483\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 14.9190 - val_loss: 203.2812\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 21.5608 - val_loss: 205.7579\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 14.1134 - val_loss: 206.5177\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 13.6376 - val_loss: 206.0320\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 15.3756 - val_loss: 207.8008\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 12.7313 - val_loss: 217.6922\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 18.4391 - val_loss: 218.2605\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 13.0535 - val_loss: 207.5087\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 11.8535 - val_loss: 210.4079\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 13.1970 - val_loss: 211.8006\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 12.5254 - val_loss: 228.4173\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 12.5326 - val_loss: 210.9653\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 10.1409 - val_loss: 215.9610\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 11.3073 - val_loss: 221.7928\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 12.2364 - val_loss: 214.1878\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 9.0296 - val_loss: 216.9956\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 9.8551 - val_loss: 215.7141\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 13.0090 - val_loss: 230.9054\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 12.9759 - val_loss: 218.9180\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 8.6635 - val_loss: 220.5108\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 8.4310 - val_loss: 217.4811\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 10.7659 - val_loss: 222.5265\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 9.4535 - val_loss: 218.0067\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 7.1544 - val_loss: 219.3379\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 7.7466 - val_loss: 218.2191\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 7.6466 - val_loss: 222.7447\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 6.5805 - val_loss: 220.0269\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 7.0718 - val_loss: 225.2413\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 6.5085 - val_loss: 221.4945\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 7.2301 - val_loss: 222.5582\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 6.2765 - val_loss: 222.4952\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 7.8066 - val_loss: 221.9889\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 6.1830 - val_loss: 221.8470\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 5.3624 - val_loss: 224.0043\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 5.7911 - val_loss: 224.3526\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 5.0929 - val_loss: 223.8113\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 4.5679 - val_loss: 228.3596\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 4.9758 - val_loss: 226.3079\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 4.6996 - val_loss: 228.4002\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 4.3385 - val_loss: 228.5549\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 4.9613 - val_loss: 229.9390\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 3.9238 - val_loss: 227.1471\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 3.9678 - val_loss: 232.6655\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 3.9316 - val_loss: 229.2848\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 3.2379 - val_loss: 228.3354\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 3.4711 - val_loss: 231.9411\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 5.1528 - val_loss: 236.9413\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 7.4470 - val_loss: 229.8724\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 6.7037 - val_loss: 231.7021\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.5597 - val_loss: 231.5859\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.4033 - val_loss: 230.5452\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 2.7813 - val_loss: 232.3792\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 2.5277 - val_loss: 232.7697\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.1867 - val_loss: 233.7902\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 2.2634 - val_loss: 233.6745\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.7670 - val_loss: 233.0042\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 3.9355 - val_loss: 232.7353\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.5676 - val_loss: 236.9825\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 2.1755 - val_loss: 233.9309\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.9682 - val_loss: 235.3727\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.8833 - val_loss: 235.3819\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.4677 - val_loss: 233.9156\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.7815 - val_loss: 236.2000\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.3295 - val_loss: 236.4730\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.2483 - val_loss: 236.6703\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.5197 - val_loss: 237.2783\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.2995 - val_loss: 237.0127\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.4879 - val_loss: 236.1808\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 1.4071 - val_loss: 238.6859\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 1.4405 - val_loss: 237.6912\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.3179 - val_loss: 237.4896\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 2.4095 - val_loss: 237.2466\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 3.0992 - val_loss: 237.7280\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.9420 - val_loss: 238.3203\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 4.4311 - val_loss: 242.3489\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.8381 - val_loss: 242.1230\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.9236 - val_loss: 235.7258\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.1537 - val_loss: 238.5133\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.1982 - val_loss: 238.2203\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.0540 - val_loss: 238.0693\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9905 - val_loss: 240.8724\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.9021 - val_loss: 240.6828\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.3295 - val_loss: 237.3012\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.8099 - val_loss: 239.0014\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.7173 - val_loss: 239.5611\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.8141 - val_loss: 239.0805\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.7790 - val_loss: 240.7228\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 1.0719 - val_loss: 239.0171\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 1.5211 - val_loss: 240.0190\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.7957 - val_loss: 239.9241\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.1497 - val_loss: 240.1589\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.9082 - val_loss: 239.0902\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.6125 - val_loss: 240.0082\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1748 - val_loss: 241.3150\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.5195 - val_loss: 241.6044\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4080 - val_loss: 240.1199\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3479 - val_loss: 240.2548\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.4755 - val_loss: 240.6408\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.8672 - val_loss: 242.0114\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.5396 - val_loss: 241.4477\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.2814 - val_loss: 241.3200\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3081 - val_loss: 240.2126\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4138 - val_loss: 242.4285\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2876 - val_loss: 242.3792\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3311 - val_loss: 243.5371\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4531 - val_loss: 242.1191\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.7012 - val_loss: 242.1895\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3517 - val_loss: 241.6120\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.9269 - val_loss: 243.1621\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 2.0812 - val_loss: 254.3402\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 23.5493 - val_loss: 232.8192\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 5.7664 - val_loss: 240.2549\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 2.2280 - val_loss: 238.9500\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.4543 - val_loss: 237.1828\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.8345 - val_loss: 240.4885\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4968 - val_loss: 238.9363\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5532 - val_loss: 238.8720\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3416 - val_loss: 239.1996\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.3161 - val_loss: 239.6649\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2411 - val_loss: 240.1102\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2223 - val_loss: 240.6262\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1811 - val_loss: 239.8727\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1561 - val_loss: 240.5072\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.2035 - val_loss: 241.0019\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2832 - val_loss: 240.8886\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2251 - val_loss: 240.5002\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1614 - val_loss: 241.0864\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1317 - val_loss: 240.4666\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1580 - val_loss: 241.3572\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2295 - val_loss: 241.5709\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2003 - val_loss: 241.3726\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5602 - val_loss: 242.1494\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6005 - val_loss: 242.9700\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.4422 - val_loss: 241.4898\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5508 - val_loss: 241.0842\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5339 - val_loss: 241.0750\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.8346 - val_loss: 239.7657\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 4.7702 - val_loss: 244.1613\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 6.7939 - val_loss: 244.3771\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 2.4481 - val_loss: 240.6827\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.5388 - val_loss: 240.3421\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.9002 - val_loss: 241.1962\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.2236 - val_loss: 240.8793\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.4285 - val_loss: 240.9583\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2889 - val_loss: 241.3150\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6408 - val_loss: 240.6127\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4031 - val_loss: 240.8204\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3892 - val_loss: 240.1497\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4305 - val_loss: 240.3059\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2105 - val_loss: 240.0856\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2891 - val_loss: 239.0514\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3230 - val_loss: 239.3930\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5109 - val_loss: 239.0293\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2462 - val_loss: 239.9507\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2110 - val_loss: 240.3626\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3358 - val_loss: 241.2051\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.5301 - val_loss: 241.2665\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5267 - val_loss: 239.9337\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4746 - val_loss: 240.2130\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3957 - val_loss: 241.2450\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.8207 - val_loss: 246.1121\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 10.0787 - val_loss: 232.0454\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 5.1588 - val_loss: 235.3866\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.3157 - val_loss: 240.5503\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.7835 - val_loss: 239.1941\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.4592 - val_loss: 237.7162\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.8010 - val_loss: 238.8350\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4238 - val_loss: 239.2906\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3458 - val_loss: 237.4690\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4044 - val_loss: 238.3332\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.2119 - val_loss: 238.8284\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1630 - val_loss: 238.6508\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1791 - val_loss: 238.7031\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3418 - val_loss: 239.4477\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4273 - val_loss: 239.9670\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.6698 - val_loss: 238.6459\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4148 - val_loss: 239.6334\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.5220 - val_loss: 237.9158\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2180 - val_loss: 238.9268\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5325 - val_loss: 242.2654\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.8596 - val_loss: 239.6859\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.6819 - val_loss: 239.5570\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.0484 - val_loss: 239.5661\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.7375 - val_loss: 240.0855\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 6.6846 - val_loss: 246.4813\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 11.7656 - val_loss: 236.3938\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 4.5213 - val_loss: 243.8752\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.8460 - val_loss: 236.7874\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.4761 - val_loss: 237.6364\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3382 - val_loss: 237.6799\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.4355 - val_loss: 238.5762\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4755 - val_loss: 239.1365\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.8026 - val_loss: 236.6007\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2780 - val_loss: 238.6239\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.2654 - val_loss: 239.2292\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.2142 - val_loss: 237.7531\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2476 - val_loss: 237.7040\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2162 - val_loss: 237.7119\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.2407 - val_loss: 237.8813\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1232 - val_loss: 238.5864\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1189 - val_loss: 239.1304\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.1212 - val_loss: 238.5910\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0913 - val_loss: 238.4137\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0666 - val_loss: 238.2197\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0659 - val_loss: 238.0454\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2376 - val_loss: 238.0921\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.8489 - val_loss: 241.5302\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 2.7713 - val_loss: 255.1708\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 3.5143 - val_loss: 238.2638\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.7483 - val_loss: 241.2361\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0407 - val_loss: 240.3674\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 1.1559 - val_loss: 242.3369\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 3.3386 - val_loss: 237.4196\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.1674 - val_loss: 237.9712\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0158 - val_loss: 235.3977\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4196 - val_loss: 237.2583\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2782 - val_loss: 237.7060\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2086 - val_loss: 236.7213\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.1512 - val_loss: 237.2030\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1415 - val_loss: 237.7933\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1631 - val_loss: 237.3100\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2046 - val_loss: 238.1387\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.2372 - val_loss: 238.8368\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1698 - val_loss: 237.5907\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0778 - val_loss: 238.0324\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1297 - val_loss: 237.1627\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.1466 - val_loss: 238.1515\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1381 - val_loss: 238.6887\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.3812 - val_loss: 238.5890\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.4147 - val_loss: 241.4887\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 2.6177 - val_loss: 237.5618\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.7234 - val_loss: 234.9872\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.6362 - val_loss: 237.3623\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.6574 - val_loss: 237.3624\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.6705 - val_loss: 240.6174\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.2027 - val_loss: 233.8305\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 1.5050 - val_loss: 239.0272\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 1.5020 - val_loss: 237.0378\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.6406 - val_loss: 237.6634\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4516 - val_loss: 236.1805\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3964 - val_loss: 237.3514\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.2639 - val_loss: 237.5012\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.2947 - val_loss: 236.5019\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1501 - val_loss: 236.2657\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2280 - val_loss: 236.6991\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.7116 - val_loss: 237.9985\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.2934 - val_loss: 235.7401\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4021 - val_loss: 236.7056\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4643 - val_loss: 236.8701\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7059 - val_loss: 236.6973\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9661 - val_loss: 238.5434\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3794 - val_loss: 235.0748\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 2.4248 - val_loss: 236.4766\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.2968 - val_loss: 239.1154\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.6169 - val_loss: 237.0794\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.7189 - val_loss: 235.2436\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.8459 - val_loss: 235.5294\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.1601 - val_loss: 236.5961\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 6.9715 - val_loss: 239.1966\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.3096 - val_loss: 236.6023\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 1.2201 - val_loss: 241.6828\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 1.0318 - val_loss: 233.7506\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.7501 - val_loss: 237.1425\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 1.4333 - val_loss: 234.2553\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 1.3693 - val_loss: 235.1723\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 4.0712 - val_loss: 234.0153\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 1.0383 - val_loss: 233.7725\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.4609 - val_loss: 232.9553\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.2240 - val_loss: 234.1517\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1757 - val_loss: 234.8708\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1668 - val_loss: 233.5162\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1080 - val_loss: 234.4186\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2400 - val_loss: 234.5729\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.5226 - val_loss: 235.1236\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4768 - val_loss: 234.0756\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.7220 - val_loss: 236.4490\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.0523 - val_loss: 241.5956\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.3242 - val_loss: 233.3107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.5845 - val_loss: 235.9326\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7185 - val_loss: 234.2133\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2902 - val_loss: 234.8945\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1574 - val_loss: 234.2026\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1468 - val_loss: 234.0404\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3883 - val_loss: 235.9336\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9202 - val_loss: 233.6952\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.5978 - val_loss: 232.3065\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.7620 - val_loss: 233.5998\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5172 - val_loss: 235.0458\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3289 - val_loss: 233.8902\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.6554 - val_loss: 236.8961\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.1495 - val_loss: 234.6951\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1290 - val_loss: 235.6497\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.8902 - val_loss: 234.2553\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.8630 - val_loss: 233.0228\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9096 - val_loss: 232.7671\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.9955 - val_loss: 233.8144\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.0049 - val_loss: 235.2292\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.5657 - val_loss: 233.1923\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.7737 - val_loss: 233.8569\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3199 - val_loss: 233.7857\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.5948 - val_loss: 235.3201\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6950 - val_loss: 231.1110\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.5649 - val_loss: 237.2414\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 3.6680 - val_loss: 232.5049\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.1379 - val_loss: 231.6965\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 3.6705 - val_loss: 233.8562\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 1.6294 - val_loss: 232.1765\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.5012 - val_loss: 231.8803\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.3335 - val_loss: 231.3971\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.5696 - val_loss: 231.9114\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5622 - val_loss: 232.3781\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.5392 - val_loss: 232.5457\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3416 - val_loss: 234.4061\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1802 - val_loss: 233.0758\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1386 - val_loss: 233.6069\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1318 - val_loss: 232.6882\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2793 - val_loss: 231.9719\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1340 - val_loss: 232.3834\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.3018 - val_loss: 232.9248\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4041 - val_loss: 232.6200\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.2064 - val_loss: 232.3324\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1364 - val_loss: 232.8448\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3114 - val_loss: 232.8276\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.7879 - val_loss: 229.5423\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.2439 - val_loss: 242.3174\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.0587 - val_loss: 236.4664\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.8340 - val_loss: 233.3752\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.5885 - val_loss: 236.1641\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.0595 - val_loss: 232.9214\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6604 - val_loss: 232.7368\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.7354 - val_loss: 232.0249\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.5089 - val_loss: 231.5694\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5694 - val_loss: 233.8487\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.6945 - val_loss: 232.9689\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3428 - val_loss: 232.5269\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.2518 - val_loss: 232.1375\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1650 - val_loss: 231.2648\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1995 - val_loss: 231.1293\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.1765 - val_loss: 231.5715\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.4068 - val_loss: 231.4320\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.2912 - val_loss: 231.4631\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2334 - val_loss: 230.1634\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.4289 - val_loss: 230.8414\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 1.7969 - val_loss: 230.8680\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 1.8879 - val_loss: 232.6323\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 11.5317 - val_loss: 256.4936\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 16.8393 - val_loss: 229.9575\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 2.5444 - val_loss: 228.0074\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.9926 - val_loss: 230.2216\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.7276 - val_loss: 229.9516\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.4095 - val_loss: 228.6717\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.3350 - val_loss: 229.3158\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.2102 - val_loss: 229.3784\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.1469 - val_loss: 228.8403\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.1187 - val_loss: 229.6707\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.0813 - val_loss: 229.9954\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.1058 - val_loss: 230.0318\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.1397 - val_loss: 230.2854\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.0948 - val_loss: 230.0438\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.0574 - val_loss: 230.4799\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.0586 - val_loss: 230.5402\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0630 - val_loss: 230.6637\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0504 - val_loss: 230.1046\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.0389 - val_loss: 230.0245\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.0722 - val_loss: 230.2396\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0731 - val_loss: 230.4981\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.0616 - val_loss: 230.4258\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0925 - val_loss: 230.7458\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0525 - val_loss: 230.7380\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1168 - val_loss: 230.3410\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.160 - 0s 108us/step - loss: 0.1344 - val_loss: 230.0109\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.2158 - val_loss: 229.4418\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.1829 - val_loss: 231.2813\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.1976 - val_loss: 230.2185\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.0797 - val_loss: 230.7519\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0874 - val_loss: 229.9685\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.2151 - val_loss: 230.9960\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 3.6419 - val_loss: 231.5384\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 4.4399 - val_loss: 226.7807\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 1.5803 - val_loss: 227.1949\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.8595 - val_loss: 229.3500\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.3614 - val_loss: 229.3245\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.1770 - val_loss: 229.9501\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2838 - val_loss: 229.9570\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6641 - val_loss: 228.8631\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.4286 - val_loss: 230.1010\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2024 - val_loss: 229.0567\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.9040 - val_loss: 232.2002\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.1804 - val_loss: 231.4687\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.7060 - val_loss: 228.6242\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.0850 - val_loss: 232.3421\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 2.1142 - val_loss: 229.8022\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.8874 - val_loss: 230.1135\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6447 - val_loss: 230.4752\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0821 - val_loss: 231.0646\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4869 - val_loss: 230.6596\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.3892 - val_loss: 228.2165\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2577 - val_loss: 229.3489\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1472 - val_loss: 229.4536\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1964 - val_loss: 229.4777\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0874 - val_loss: 229.3820\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0732 - val_loss: 229.7964\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1335 - val_loss: 230.0078\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.6716 - val_loss: 229.5947\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4146 - val_loss: 228.7243\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1868 - val_loss: 229.3039\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.1694 - val_loss: 229.5795\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1810 - val_loss: 228.8058\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3884 - val_loss: 228.9284\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3590 - val_loss: 228.7824\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2533 - val_loss: 229.1328\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5445 - val_loss: 229.4930\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.3570 - val_loss: 236.2428\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 3.0695 - val_loss: 232.3400\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.0169 - val_loss: 230.7167\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.6887 - val_loss: 230.5282\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 5.7625 - val_loss: 231.5369\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 3.1043 - val_loss: 228.7763\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1412 - val_loss: 229.9505\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.2308 - val_loss: 229.4071\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.7647 - val_loss: 227.8937\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5397 - val_loss: 229.3290\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.2304 - val_loss: 227.1831\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.3002 - val_loss: 231.9384\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.5065 - val_loss: 228.5849\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.8492 - val_loss: 228.2144\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.3912 - val_loss: 228.0326\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4998 - val_loss: 228.2144\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7334 - val_loss: 227.5308\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.4007 - val_loss: 227.7308\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3288 - val_loss: 226.5866\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1632 - val_loss: 229.1290\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1004 - val_loss: 228.2418\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0880 - val_loss: 227.7685\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9571 - val_loss: 227.9965\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.7832 - val_loss: 229.9350\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 2.3889 - val_loss: 231.2019\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 2.4457 - val_loss: 229.4569\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9149 - val_loss: 228.2124\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.7630 - val_loss: 223.9758\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7890 - val_loss: 229.9362\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.6035 - val_loss: 227.3107\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2299 - val_loss: 227.2211\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1506 - val_loss: 227.1024\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1494 - val_loss: 227.6488\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1041 - val_loss: 227.4496\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1017 - val_loss: 227.2538\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1084 - val_loss: 228.1787\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1153 - val_loss: 227.0657\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0894 - val_loss: 227.4661\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1455 - val_loss: 227.8718\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.1519 - val_loss: 227.3554\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1110 - val_loss: 227.3327\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0770 - val_loss: 228.1831\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1443 - val_loss: 227.7528\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1744 - val_loss: 227.5771\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.5285 - val_loss: 230.8322\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.3048 - val_loss: 226.2955\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0935 - val_loss: 224.6253\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 5.4454 - val_loss: 235.1354\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 4.4302 - val_loss: 227.4668\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.3474 - val_loss: 224.0189\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.7529 - val_loss: 224.2870\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5695 - val_loss: 226.0470\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3079 - val_loss: 226.8771\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.2671 - val_loss: 225.6635\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1388 - val_loss: 225.4567\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1193 - val_loss: 225.9938\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1517 - val_loss: 225.3517\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2901 - val_loss: 226.8835\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6217 - val_loss: 224.4387\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.5905 - val_loss: 226.6829\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4519 - val_loss: 225.2257\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2592 - val_loss: 225.3429\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3740 - val_loss: 226.3586\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4183 - val_loss: 227.0413\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2742 - val_loss: 225.6304\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.7923 - val_loss: 228.0959\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 2.5856 - val_loss: 226.5260\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 2.5636 - val_loss: 233.7997\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.6404 - val_loss: 224.8779\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4695 - val_loss: 225.5871\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.6050 - val_loss: 226.1755\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.5456 - val_loss: 225.4078\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3385 - val_loss: 224.6111\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2021 - val_loss: 226.4683\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1460 - val_loss: 226.4573\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2132 - val_loss: 226.2925\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2003 - val_loss: 224.7605\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.2289 - val_loss: 226.4586\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4514 - val_loss: 224.8059\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.0893 - val_loss: 225.6843\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.0399 - val_loss: 226.3233\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.4063 - val_loss: 227.0776\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.9510 - val_loss: 224.9851\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.4620 - val_loss: 225.5247\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.7241 - val_loss: 225.3901\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7245 - val_loss: 225.5730\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.8852 - val_loss: 225.0742\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.2856 - val_loss: 225.1519\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.5159 - val_loss: 225.2133\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5472 - val_loss: 225.1079\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4785 - val_loss: 223.9567\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.3874 - val_loss: 225.1477\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0417 - val_loss: 225.8373\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6813 - val_loss: 225.8174\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3559 - val_loss: 225.0692\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4440 - val_loss: 225.5260\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4353 - val_loss: 226.0155\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4342 - val_loss: 225.9960\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4293 - val_loss: 226.6399\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4819 - val_loss: 225.2651\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3383 - val_loss: 225.0123\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.2260 - val_loss: 238.7356\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 9.4441 - val_loss: 223.3734\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 2.3758 - val_loss: 222.1412\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9640 - val_loss: 224.2112\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2586 - val_loss: 224.5523\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4303 - val_loss: 224.0133\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.4359 - val_loss: 224.7655\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.3006 - val_loss: 223.5847\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.1691 - val_loss: 222.8441\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2436 - val_loss: 224.9017\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1095 - val_loss: 224.2383\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1229 - val_loss: 224.0065\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1642 - val_loss: 224.5518\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.1682 - val_loss: 224.9404\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.1045 - val_loss: 223.8702\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.0393 - val_loss: 224.2317\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0283 - val_loss: 224.2518\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.0417 - val_loss: 224.8147\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1453 - val_loss: 224.1881\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4210 - val_loss: 226.6802\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4246 - val_loss: 223.5180\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4513 - val_loss: 226.1212\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.3459 - val_loss: 226.6411\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 4.3354 - val_loss: 249.7226\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 8.9356 - val_loss: 231.0500\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 3.0428 - val_loss: 222.6790\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 7.9983 - val_loss: 233.4649\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.5283 - val_loss: 224.2571\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.2258 - val_loss: 224.5279\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.4963 - val_loss: 224.0771\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.4223 - val_loss: 223.2831\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2905 - val_loss: 223.6111\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.1787 - val_loss: 222.9615\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2003 - val_loss: 223.2713\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0969 - val_loss: 223.8279\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0821 - val_loss: 223.7399\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0533 - val_loss: 223.4967\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0467 - val_loss: 223.6247\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.0589 - val_loss: 223.2483\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0415 - val_loss: 223.5435\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0442 - val_loss: 224.1095\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0301 - val_loss: 223.7100\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.0347 - val_loss: 224.1445\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0313 - val_loss: 223.8412\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0319 - val_loss: 224.0939\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.0670 - val_loss: 223.7853\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0628 - val_loss: 224.3568\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0970 - val_loss: 223.9003\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.0719 - val_loss: 224.8679\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0838 - val_loss: 223.8687\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.0923 - val_loss: 224.0537\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0997 - val_loss: 224.1741\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0578 - val_loss: 224.1201\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0360 - val_loss: 223.2107\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6342 - val_loss: 223.7523\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.8528 - val_loss: 224.5292\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.1206 - val_loss: 227.5797\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.8051 - val_loss: 225.8988\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.7446 - val_loss: 221.9561\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 2.3716 - val_loss: 223.6312\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2175 - val_loss: 222.0015\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9463 - val_loss: 222.6549\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.6117 - val_loss: 223.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4786 - val_loss: 223.2526\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3457 - val_loss: 222.6687\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5232 - val_loss: 223.3856\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2578 - val_loss: 222.7041\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2072 - val_loss: 223.0857\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.0713 - val_loss: 224.4319\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.1016 - val_loss: 222.7709\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5892 - val_loss: 222.8911\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.5836 - val_loss: 222.6961\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.9236 - val_loss: 222.0267\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.5589 - val_loss: 223.0777\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.6523 - val_loss: 223.2832\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.4343 - val_loss: 224.5116\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2119 - val_loss: 223.7816\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1718 - val_loss: 222.3019\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5552 - val_loss: 224.9884\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.5917 - val_loss: 223.5754\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2328 - val_loss: 223.8412\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 2.1658 - val_loss: 224.1876\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.3713 - val_loss: 221.3444\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.6664 - val_loss: 223.1062\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.0627 - val_loss: 222.4681\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.6907 - val_loss: 223.6515\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6076 - val_loss: 223.4843\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.7612 - val_loss: 224.2829\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2056 - val_loss: 226.3262\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.0822 - val_loss: 222.1412\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7231 - val_loss: 224.3557\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2921 - val_loss: 225.9449\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.7915 - val_loss: 222.4760\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 2.7341 - val_loss: 224.6558\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 2.1117 - val_loss: 223.5801\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 1.2957 - val_loss: 221.9915\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.4813 - val_loss: 222.1542\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2111 - val_loss: 221.9258\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.2634 - val_loss: 222.7039\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.1688 - val_loss: 222.2434\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.1908 - val_loss: 221.4509\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2403 - val_loss: 223.1407\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4519 - val_loss: 222.6278\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2783 - val_loss: 222.3450\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.6204 - val_loss: 230.2898\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.1834 - val_loss: 224.8028\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 2.7334 - val_loss: 222.1828\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.7309 - val_loss: 221.0136\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1258 - val_loss: 223.1419\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1769 - val_loss: 221.6515\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4400 - val_loss: 222.2388\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.2797 - val_loss: 222.3725\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3447 - val_loss: 221.4767\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2348 - val_loss: 222.9374\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1776 - val_loss: 222.4449\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0899 - val_loss: 223.2309\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1668 - val_loss: 222.6994\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.4968 - val_loss: 222.9134\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5014 - val_loss: 222.5017\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3568 - val_loss: 221.8575\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3285 - val_loss: 221.8953\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3684 - val_loss: 221.0709\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3650 - val_loss: 221.2206\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3234 - val_loss: 220.4523\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3700 - val_loss: 221.7066\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4163 - val_loss: 221.5682\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7331 - val_loss: 221.7606\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5124 - val_loss: 221.8345\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2670 - val_loss: 221.0442\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4156 - val_loss: 222.2066\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.2860 - val_loss: 220.6498\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 2.3536 - val_loss: 221.1856\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.9987 - val_loss: 220.9107\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.6088 - val_loss: 222.1446\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.2490 - val_loss: 220.2923\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 3.3756 - val_loss: 219.0717\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.1936 - val_loss: 220.5122\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 2.1763 - val_loss: 220.1797\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.8186 - val_loss: 218.9881\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4949 - val_loss: 219.0306\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.8642 - val_loss: 219.6176\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5020 - val_loss: 220.1066\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.2235 - val_loss: 218.4751\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2219 - val_loss: 220.2805\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2905 - val_loss: 219.9614\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1744 - val_loss: 220.9769\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1407 - val_loss: 220.9125\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1404 - val_loss: 220.7211\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1107 - val_loss: 220.4207\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1100 - val_loss: 219.5108\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1931 - val_loss: 219.7611\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.2511 - val_loss: 220.5432\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3440 - val_loss: 219.9459\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.1228 - val_loss: 224.1050\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.4888 - val_loss: 220.9079\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.1135 - val_loss: 222.8154\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.8748 - val_loss: 223.9500\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.9162 - val_loss: 218.3461\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.4967 - val_loss: 222.7590\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9577 - val_loss: 222.2531\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.5235 - val_loss: 222.1496\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2153 - val_loss: 221.6792\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1496 - val_loss: 220.1253\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1822 - val_loss: 220.0715\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.4725 - val_loss: 220.2683\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.6026 - val_loss: 221.7371\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4048 - val_loss: 220.2528\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2072 - val_loss: 221.5932\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1328 - val_loss: 220.2962\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2510 - val_loss: 219.1050\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2678 - val_loss: 220.4801\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.3353 - val_loss: 221.4068\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3767 - val_loss: 220.2777\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3715 - val_loss: 219.0185\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1819 - val_loss: 220.1379\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1080 - val_loss: 220.5885\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3811 - val_loss: 221.8976\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5575 - val_loss: 219.4175\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.9218 - val_loss: 220.9229\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.8160 - val_loss: 220.4976\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.9907 - val_loss: 219.9111\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.0347 - val_loss: 219.9756\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4677 - val_loss: 219.9482\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.2937 - val_loss: 220.2978\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3107 - val_loss: 220.3756\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0581 - val_loss: 223.2542\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 7.0277 - val_loss: 222.9972\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 4.5325 - val_loss: 220.5237\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 1.6571 - val_loss: 219.6581\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.9296 - val_loss: 217.6921\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3747 - val_loss: 221.0619\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2339 - val_loss: 220.2723\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1905 - val_loss: 220.4832\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1220 - val_loss: 220.0155\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0997 - val_loss: 220.6927\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0954 - val_loss: 220.1756\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1609 - val_loss: 220.3643\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1280 - val_loss: 221.0296\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0978 - val_loss: 219.6554\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0561 - val_loss: 219.9577\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0317 - val_loss: 220.3703\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0358 - val_loss: 220.3251\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0374 - val_loss: 220.2898\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0985 - val_loss: 220.3908\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5113 - val_loss: 220.8690\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.8623 - val_loss: 219.9038\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.8049 - val_loss: 219.9196\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 4.0969 - val_loss: 220.1173\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 4.1542 - val_loss: 220.0208\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 3.1946 - val_loss: 219.7699\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.0035 - val_loss: 219.4276\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.6269 - val_loss: 222.3725\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.3494 - val_loss: 220.2680\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1834 - val_loss: 219.4627\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1675 - val_loss: 220.1821\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1319 - val_loss: 219.7556\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2362 - val_loss: 219.9750\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2305 - val_loss: 220.7080\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1256 - val_loss: 219.6640\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0580 - val_loss: 219.7460\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0625 - val_loss: 220.1413\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0649 - val_loss: 220.2021\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0664 - val_loss: 220.2984\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0515 - val_loss: 220.3086\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0535 - val_loss: 220.5395\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0310 - val_loss: 220.2851\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0354 - val_loss: 220.3421\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.1969 - val_loss: 220.3249\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.2923 - val_loss: 220.0026\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2815 - val_loss: 220.1240\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7037 - val_loss: 219.6279\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.1253 - val_loss: 219.5979\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 2.0663 - val_loss: 222.2317\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.5765 - val_loss: 219.8979\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.4273 - val_loss: 217.9141\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.9068 - val_loss: 220.4231\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.3551 - val_loss: 219.6195\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.4450 - val_loss: 219.1858\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2105 - val_loss: 219.9601\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.1631 - val_loss: 219.9748\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1855 - val_loss: 219.8593\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1187 - val_loss: 219.6478\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1878 - val_loss: 219.5361\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.1558 - val_loss: 219.2057\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.1367 - val_loss: 219.3846\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.2537 - val_loss: 220.0014\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.7927 - val_loss: 219.7026\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.1301 - val_loss: 223.9313\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.8956 - val_loss: 217.9594\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1550 - val_loss: 222.8482\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 3.4644 - val_loss: 218.0439\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.5314 - val_loss: 219.2739\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.7327 - val_loss: 218.9997\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.3593 - val_loss: 220.7560\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2484 - val_loss: 218.9211\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2121 - val_loss: 218.4398\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.2279 - val_loss: 218.0492\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4978 - val_loss: 220.6684\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7297 - val_loss: 218.6581\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4117 - val_loss: 219.9417\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.8996 - val_loss: 217.5758\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.8227 - val_loss: 218.4952\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4760 - val_loss: 219.3126\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3003 - val_loss: 220.9101\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.5767 - val_loss: 218.0724\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.8946 - val_loss: 219.4120\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.7338 - val_loss: 218.7697\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.4078 - val_loss: 218.4004\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.2876 - val_loss: 219.1523\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.2039 - val_loss: 218.3284\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.1495 - val_loss: 218.6910\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.2061 - val_loss: 218.4827\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.3937 - val_loss: 219.5524\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.8692 - val_loss: 219.0092\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.3346 - val_loss: 218.2573\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.7078 - val_loss: 218.9149\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3843 - val_loss: 217.9453\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.0894 - val_loss: 221.0946\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.2145 - val_loss: 220.2147\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.6250 - val_loss: 218.7444\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.7882 - val_loss: 219.9066\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.8892 - val_loss: 218.7561\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 1.5591 - val_loss: 220.9084\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.8141 - val_loss: 217.2634\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2728 - val_loss: 222.8947\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.8761 - val_loss: 218.0538\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3362 - val_loss: 219.4646\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1524 - val_loss: 218.5502\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1109 - val_loss: 219.0426\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.3514 - val_loss: 219.2996\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2696 - val_loss: 218.2329\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.2880 - val_loss: 218.3596\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.3403 - val_loss: 218.1135\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.2320 - val_loss: 218.3186\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.0767 - val_loss: 218.5386\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.1665 - val_loss: 219.6475\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.5189 - val_loss: 219.3692\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 5.3102 - val_loss: 219.4611\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 5.6190 - val_loss: 212.6081\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.4521 - val_loss: 220.1877\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.0684 - val_loss: 219.4820\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.6449 - val_loss: 217.9378\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.5565 - val_loss: 218.9502\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.5197 - val_loss: 218.1132\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3003 - val_loss: 217.6703\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3253 - val_loss: 217.7433\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2103 - val_loss: 218.0428\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0956 - val_loss: 218.3395\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.0677 - val_loss: 217.9414\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0755 - val_loss: 218.4902\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0786 - val_loss: 218.5317\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0848 - val_loss: 218.1349\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0531 - val_loss: 218.3870\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0981 - val_loss: 218.2649\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0489 - val_loss: 218.3848\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.0847 - val_loss: 218.1685\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.0462 - val_loss: 218.2376\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0709 - val_loss: 218.5053\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 80us/step\n",
      "262.5463470458984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "    \n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "        \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "\n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts: \n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "        \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
